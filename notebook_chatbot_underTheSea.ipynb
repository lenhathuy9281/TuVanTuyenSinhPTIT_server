{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Xây dựng Chatbot sử dụng mô hình Transformer"
      ],
      "metadata": {
        "id": "N10v8EqGI1Ro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WLyemtemCHJ",
        "outputId": "b652c47d-49eb-49d3-fe24-08719f6245ba"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install underthesea"
      ],
      "metadata": {
        "id": "s16yZMa6JCQt",
        "outputId": "4968e476-cc82-4ef4-866c-9c2e5c4b8574",
        "execution": {
          "iopub.status.busy": "2022-05-22T11:01:00.037542Z",
          "iopub.execute_input": "2022-05-22T11:01:00.038151Z",
          "iopub.status.idle": "2022-05-22T11:01:08.997711Z",
          "shell.execute_reply.started": "2022-05-22T11:01:00.03805Z",
          "shell.execute_reply": "2022-05-22T11:01:08.995736Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting underthesea\n",
            "  Downloading underthesea-6.8.0-py3-none-any.whl (20.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from underthesea) (8.1.7)\n",
            "Collecting python-crfsuite>=0.9.6 (from underthesea)\n",
            "  Downloading python_crfsuite-0.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (993 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.5/993.5 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from underthesea) (3.8.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from underthesea) (4.66.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from underthesea) (2.31.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from underthesea) (1.3.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from underthesea) (1.2.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from underthesea) (6.0.1)\n",
            "Collecting underthesea-core==1.0.4 (from underthesea)\n",
            "  Downloading underthesea_core-1.0.4-cp310-cp310-manylinux2010_x86_64.whl (657 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m657.8/657.8 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->underthesea) (2023.6.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea) (2023.11.17)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->underthesea) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->underthesea) (1.11.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->underthesea) (3.2.0)\n",
            "Installing collected packages: underthesea-core, python-crfsuite, underthesea\n",
            "Successfully installed python-crfsuite-0.9.9 underthesea-6.8.0 underthesea-core-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re,string\n",
        "from gensim.models import KeyedVectors\n",
        "from collections import Counter\n",
        "from underthesea import word_tokenize\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import preprocessing, utils, activations\n",
        "# from keras.callbacks import ModelCheckpoint\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "BECuUXItI1o5",
        "execution": {
          "iopub.status.busy": "2022-05-22T11:01:08.999607Z",
          "iopub.execute_input": "2022-05-22T11:01:08.999907Z",
          "iopub.status.idle": "2022-05-22T11:01:11.708402Z",
          "shell.execute_reply.started": "2022-05-22T11:01:08.999876Z",
          "shell.execute_reply": "2022-05-22T11:01:11.70767Z"
        },
        "trusted": true
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print('Device:', tpu.master())\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "except:\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "print('Number of replicas:', strategy.num_replicas_in_sync)\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T11:01:16.337083Z",
          "iopub.execute_input": "2022-05-22T11:01:16.337357Z",
          "iopub.status.idle": "2022-05-22T11:01:16.345568Z",
          "shell.execute_reply.started": "2022-05-22T11:01:16.337326Z",
          "shell.execute_reply": "2022-05-22T11:01:16.344771Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIr_j5vhAWUe",
        "outputId": "957df065-9f65-48b6-db80-670c3380eb74"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of replicas: 1\n",
            "2.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/do_an/du_lieu_chatbot.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "_Va-SWVOJLeO",
        "outputId": "b555914e-ecfd-4845-cbce-dca3252984c6",
        "execution": {
          "iopub.status.busy": "2022-05-22T11:01:19.362555Z",
          "iopub.execute_input": "2022-05-22T11:01:19.36307Z",
          "iopub.status.idle": "2022-05-22T11:01:19.394986Z",
          "shell.execute_reply.started": "2022-05-22T11:01:19.363034Z",
          "shell.execute_reply": "2022-05-22T11:01:19.39423Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                   user_a  \\\n",
              "0           1                    thông tin trường PTIT   \n",
              "1           2  thông tin học viện bưu chính viễn thông   \n",
              "2           3               thông tin trường bưu chính   \n",
              "3           4                  thông tin học viện PTIT   \n",
              "4           5                           thông tin PTIT   \n",
              "\n",
              "                                              user_b  \n",
              "0  Học viện Công nghệ Thông tin (PTIT) tại Hà Nội...  \n",
              "1  Học viện Công nghệ Thông tin (PTIT) tại Hà Nội...  \n",
              "2  Học viện Công nghệ Thông tin (PTIT) tại Hà Nội...  \n",
              "3  Học viện Công nghệ Thông tin (PTIT) tại Hà Nội...  \n",
              "4  Học viện Công nghệ Thông tin (PTIT) tại Hà Nội...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b146c350-5c2c-45f1-bea1-56d0bb47265a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>user_a</th>\n",
              "      <th>user_b</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>thông tin trường PTIT</td>\n",
              "      <td>Học viện Công nghệ Thông tin (PTIT) tại Hà Nội...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>thông tin học viện bưu chính viễn thông</td>\n",
              "      <td>Học viện Công nghệ Thông tin (PTIT) tại Hà Nội...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>thông tin trường bưu chính</td>\n",
              "      <td>Học viện Công nghệ Thông tin (PTIT) tại Hà Nội...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>thông tin học viện PTIT</td>\n",
              "      <td>Học viện Công nghệ Thông tin (PTIT) tại Hà Nội...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>thông tin PTIT</td>\n",
              "      <td>Học viện Công nghệ Thông tin (PTIT) tại Hà Nội...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b146c350-5c2c-45f1-bea1-56d0bb47265a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b146c350-5c2c-45f1-bea1-56d0bb47265a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b146c350-5c2c-45f1-bea1-56d0bb47265a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-67dc9cba-cae8-48a2-aab6-e71a6faa1090\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-67dc9cba-cae8-48a2-aab6-e71a6faa1090')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-67dc9cba-cae8-48a2-aab6-e71a6faa1090 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "7pSEtATtj5VL",
        "outputId": "09e4c63f-2dee-4ef7-934e-3a97ea44e7c5",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(105, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text Cleaning / Preprocessing**"
      ],
      "metadata": {
        "id": "WHl7tRh9lO9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "UkcfrZNKlm9i",
        "outputId": "65ca9775-f548-4611-f894-24f999939b1a",
        "execution": {
          "iopub.status.busy": "2022-05-22T11:01:24.18848Z",
          "iopub.execute_input": "2022-05-22T11:01:24.188844Z",
          "iopub.status.idle": "2022-05-22T11:01:24.200673Z",
          "shell.execute_reply.started": "2022-05-22T11:01:24.188808Z",
          "shell.execute_reply": "2022-05-22T11:01:24.199782Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0     0\n",
              "user_a         0\n",
              "user_b        21\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = df[df['user_b'].isnull()].index.tolist() # Get index of nan row\n",
        "print('Question of nan answer: ' ,df['user_a'][idx].values)"
      ],
      "metadata": {
        "id": "6rEQUmGqhPJY",
        "outputId": "c07de418-b395-458e-f528-8e04bb845a54",
        "execution": {
          "iopub.status.busy": "2022-05-22T11:01:28.421938Z",
          "iopub.execute_input": "2022-05-22T11:01:28.422205Z",
          "iopub.status.idle": "2022-05-22T11:01:28.432702Z",
          "shell.execute_reply.started": "2022-05-22T11:01:28.422177Z",
          "shell.execute_reply": "2022-05-22T11:01:28.429626Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question of nan answer:  ['Công nghệ đa phương tiện là gì?'\n",
            " 'Công nghệ đa phương tiện bao gồm những gì?'\n",
            " 'thông tin ngành công nghệ kỹ thuật điện tử'\n",
            " 'thông tin ngành công nghệ đa phương tiện'\n",
            " 'thông tin ngành truyền thông đa phương tiện' 'thông tin ngành marketing'\n",
            " 'thông tin ngành quản trị kinh doanh' 'thông tin ngành kế toán'\n",
            " 'thông tin ngành thương mại điện tử'\n",
            " 'thông tin ngành công nghệ tài chính Fintech'\n",
            " 'thông tin ngành kỹ thuật điều khiển và tự động hoá'\n",
            " 'thông tin ngành khoa học máy tính' 'thông tin ngành báo chí '\n",
            " 'thông tin ngành công nghệ thông tin chất lượng cao'\n",
            " 'thông tin ngành công nghệ thông tin (cử nhân, định hướng ứng dụng)'\n",
            " 'thông tin ngành mạng máy tính và truyền thông dữ liệu'\n",
            " 'xét tuyển như thế nào' 'mình xin thông tin xét tuyển'\n",
            " 'có các phương thức xét tuyển nào' 'thông tin về phương thức xét tuyển'\n",
            " 'có thể xét tuyển như thế nào']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill in nan row value\n",
        "df['user_b'] = df['user_b'].fillna('chatbot').values"
      ],
      "metadata": {
        "id": "shyshZ51lsWG",
        "execution": {
          "iopub.status.busy": "2022-05-22T11:01:32.793152Z",
          "iopub.execute_input": "2022-05-22T11:01:32.793942Z",
          "iopub.status.idle": "2022-05-22T11:01:32.79899Z",
          "shell.execute_reply.started": "2022-05-22T11:01:32.793894Z",
          "shell.execute_reply": "2022-05-22T11:01:32.798338Z"
        },
        "trusted": true
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing\n",
        "EMOTICONS = {\n",
        "    u\":-3\":\"Happy face smiley\",\n",
        "    u\":3\":\"Happy face smiley\",\n",
        "    u\":->\":\"Happy face smiley\",\n",
        "    u\":>\":\"Happy face smiley\",\n",
        "    u\":))\":\"Happy face smiley\",\n",
        "    u\":)))\":\"Happy face smiley\",\n",
        "    u\":))))\":\"Happy face smiley\",\n",
        "    u\":'<\":\"Happy face smiley\",\n",
        "    u\":)\":\"Happy face smiley\",\n",
        "    u\":(\":\"Happy face smiley\",\n",
        "    u\":((\":\"Happy face smiley\",\n",
        "    u\":‑D\":\"Laughing, big grin or laugh with glasses\",\n",
        "    u\":D\":\"Laughing, big grin or laugh with glasses\",\n",
        "    u\"XD\":\"Laughing, big grin or laugh with glasses\",\n",
        "    u\"=D\":\"Laughing, big grin or laugh with glasses\",\n",
        "    u\":‑c\":\"Frown, sad, andry or pouting\",\n",
        "    u\":c\":\"Frown, sad, andry or pouting\",\n",
        "    u\":‑<\":\"Frown, sad, andry or pouting\",\n",
        "    u\":<\":\"Frown, sad, andry or pouting\",\n",
        "    u\":@\":\"Frown, sad, andry or pouting\",\n",
        "    u\"D:\":\"Sadness\",\n",
        "    u\":O\":\"Surprise\",\n",
        "    u\":o\":\"Surprise\",\n",
        "}\n",
        "\n",
        "cnt = Counter()\n",
        "for text in df[\"user_b\"].values:\n",
        "    for word in text.split():\n",
        "        cnt[word] += 1\n",
        "\n",
        "RAREWORDS = set([w for (w, wc) in cnt.most_common()[:-10-1:-1]]) #Get top 10 rare word\n",
        "\n",
        "def remove_emoticons(text):\n",
        "    \"Function to remove emoticons\"\n",
        "    arr = [word for word in text.split() if word not in EMOTICONS.keys()]\n",
        "    return \" \".join(arr)\n",
        "\n",
        "def remove_rarewords(text):\n",
        "    \"\"\"custom function to remove the rare words\"\"\"\n",
        "    return \" \".join([word for word in str(text).split() if word not in RAREWORDS])\n",
        "\n",
        "def preprocessing(df):\n",
        "  df[\"user_a\"] = df[\"user_a\"].apply(lambda ele: ele.translate(str.maketrans('', '', string.punctuation))) # Remove punctuation\n",
        "  df[\"user_b\"] = df[\"user_b\"].apply(lambda ele: ele.translate(str.maketrans('', '', string.punctuation)))\n",
        "  df[\"user_a\"] = df[\"user_a\"].apply(lambda ele: remove_emoticons(ele)) # Remove emoticons\n",
        "  df[\"user_b\"] = df[\"user_b\"].apply(lambda ele: remove_emoticons(ele))\n",
        "  df[\"user_a\"] = df[\"user_a\"].apply(lambda ele: remove_rarewords(ele)) # Remove rarewords\n",
        "  df[\"user_b\"] = df[\"user_b\"].apply(lambda ele: remove_rarewords(ele))\n",
        "  df['user_b'] = df['user_b'].apply(lambda ele: 'START ' + ele + ' END')\n",
        "  df[\"user_a\"] = df[\"user_a\"].apply(lambda ele: ele.lower()) # convert text to lowercase\n",
        "  df[\"user_b\"] = df[\"user_b\"].apply(lambda ele: ele.lower())\n",
        "\n",
        "  return df\n",
        "\n",
        "df = preprocessing(df)"
      ],
      "metadata": {
        "id": "hYVnIqkEJTTj",
        "execution": {
          "iopub.status.busy": "2022-05-22T11:01:37.085827Z",
          "iopub.execute_input": "2022-05-22T11:01:37.086319Z",
          "iopub.status.idle": "2022-05-22T11:01:37.207651Z",
          "shell.execute_reply.started": "2022-05-22T11:01:37.086264Z",
          "shell.execute_reply": "2022-05-22T11:01:37.206998Z"
        },
        "trusted": true
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = df.values #numpy\n",
        "questions = data[:,1] # convert question to a list\n",
        "answers = data[:,2] # convert answer that match with question to list\n",
        "print(questions[:5])\n",
        "print(answers[:5])"
      ],
      "metadata": {
        "id": "hHcACgVuJWQf",
        "outputId": "50a15c73-1190-41ce-8d29-604306b160fa",
        "execution": {
          "iopub.status.busy": "2022-05-22T11:01:41.656079Z",
          "iopub.execute_input": "2022-05-22T11:01:41.656481Z",
          "iopub.status.idle": "2022-05-22T11:01:41.664603Z",
          "shell.execute_reply.started": "2022-05-22T11:01:41.656441Z",
          "shell.execute_reply": "2022-05-22T11:01:41.663646Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['thông tin trường ptit' 'thông tin học viện bưu chính viễn thông'\n",
            " 'thông tin trường bưu chính' 'thông tin học viện ptit' 'thông tin ptit']\n",
            "['start học viện công nghệ thông tin ptit tại hà nội việt nam được thành lập vào năm 2006 và đã nhanh chóng phát triển thành một trong những cơ sở đào tạo hàng đầu về công nghệ thông tin ptit cung cấp nhiều chương trình đào tạo cử nhân và thạc sĩ trong các lĩnh vực như kỹ thuật phần mềm an toàn thông tin trí tuệ nhân tạo và các lĩnh vực công nghệ khác ngoài ra học viện này tích cực tham gia nghiên cứu và phát triển công nghệ sử dụng cơ sở hạ tầng hiện đại để hỗ trợ sinh viên và dự án nghiên cứu end'\n",
            " 'start học viện công nghệ thông tin ptit tại hà nội việt nam được thành lập vào năm 2006 và đã nhanh chóng phát triển thành một trong những cơ sở đào tạo hàng đầu về công nghệ thông tin ptit cung cấp nhiều chương trình đào tạo cử nhân và thạc sĩ trong các lĩnh vực như kỹ thuật phần mềm an toàn thông tin trí tuệ nhân tạo và các lĩnh vực công nghệ khác ngoài ra học viện này tích cực tham gia nghiên cứu và phát triển công nghệ sử dụng cơ sở hạ tầng hiện đại để hỗ trợ sinh viên và dự án nghiên cứu end'\n",
            " 'start học viện công nghệ thông tin ptit tại hà nội việt nam được thành lập vào năm 2006 và đã nhanh chóng phát triển thành một trong những cơ sở đào tạo hàng đầu về công nghệ thông tin ptit cung cấp nhiều chương trình đào tạo cử nhân và thạc sĩ trong các lĩnh vực như kỹ thuật phần mềm an toàn thông tin trí tuệ nhân tạo và các lĩnh vực công nghệ khác ngoài ra học viện này tích cực tham gia nghiên cứu và phát triển công nghệ sử dụng cơ sở hạ tầng hiện đại để hỗ trợ sinh viên và dự án nghiên cứu end'\n",
            " 'start học viện công nghệ thông tin ptit tại hà nội việt nam được thành lập vào năm 2006 và đã nhanh chóng phát triển thành một trong những cơ sở đào tạo hàng đầu về công nghệ thông tin ptit cung cấp nhiều chương trình đào tạo cử nhân và thạc sĩ trong các lĩnh vực như kỹ thuật phần mềm an toàn thông tin trí tuệ nhân tạo và các lĩnh vực công nghệ khác ngoài ra học viện này tích cực tham gia nghiên cứu và phát triển công nghệ sử dụng cơ sở hạ tầng hiện đại để hỗ trợ sinh viên và dự án nghiên cứu end'\n",
            " 'start học viện công nghệ thông tin ptit tại hà nội việt nam được thành lập vào năm 2006 và đã nhanh chóng phát triển thành một trong những cơ sở đào tạo hàng đầu về công nghệ thông tin ptit cung cấp nhiều chương trình đào tạo cử nhân và thạc sĩ trong các lĩnh vực như kỹ thuật phần mềm an toàn thông tin trí tuệ nhân tạo và các lĩnh vực công nghệ khác ngoài ra học viện này tích cực tham gia nghiên cứu và phát triển công nghệ sử dụng cơ sở hạ tầng hiện đại để hỗ trợ sinh viên và dự án nghiên cứu end']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenization and Encode, Decode**"
      ],
      "metadata": {
        "id": "3GalJfC-yhwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization questions\n",
        "questions = [word_tokenize(ques) for ques in questions]\n",
        "print(len(questions))\n",
        "print(questions[:3])"
      ],
      "metadata": {
        "id": "tM0OEAcmJZZY",
        "outputId": "4a94871f-6f2d-4f13-9c51-f1f2e737bce9",
        "execution": {
          "iopub.status.busy": "2022-05-22T11:01:47.250841Z",
          "iopub.execute_input": "2022-05-22T11:01:47.251126Z",
          "iopub.status.idle": "2022-05-22T11:01:48.594749Z",
          "shell.execute_reply.started": "2022-05-22T11:01:47.251094Z",
          "shell.execute_reply": "2022-05-22T11:01:48.593994Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "105\n",
            "[['thông tin', 'trường', 'ptit'], ['thông tin', 'học viện', 'bưu chính', 'viễn thông'], ['thông tin', 'trường', 'bưu chính']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization answer\n",
        "answers = [word_tokenize(ans) for ans in answers]\n",
        "print(len(answers))\n",
        "print(answers[:3])"
      ],
      "metadata": {
        "id": "axGM_AzyKMP-",
        "outputId": "cf34e9fc-0f84-4c7c-e65d-d0ae01439b69",
        "execution": {
          "iopub.status.busy": "2022-05-22T11:01:50.505003Z",
          "iopub.execute_input": "2022-05-22T11:01:50.505611Z",
          "iopub.status.idle": "2022-05-22T11:01:51.895971Z",
          "shell.execute_reply.started": "2022-05-22T11:01:50.505566Z",
          "shell.execute_reply": "2022-05-22T11:01:51.895105Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "105\n",
            "[['start', 'học viện', 'công nghệ thông tin', 'ptit', 'tại', 'hà nội', 'việt nam', 'được', 'thành lập', 'vào', 'năm', '2006', 'và', 'đã', 'nhanh chóng', 'phát triển', 'thành', 'một', 'trong', 'những', 'cơ sở', 'đào tạo', 'hàng đầu', 'về', 'công nghệ thông tin', 'ptit', 'cung cấp', 'nhiều', 'chương trình', 'đào tạo', 'cử nhân', 'và', 'thạc sĩ', 'trong', 'các', 'lĩnh vực', 'như', 'kỹ thuật', 'phần mềm', 'an toàn', 'thông tin', 'trí tuệ', 'nhân tạo', 'và', 'các', 'lĩnh vực', 'công nghệ', 'khác', 'ngoài ra', 'học viện', 'này', 'tích cực', 'tham gia', 'nghiên cứu', 'và', 'phát triển', 'công nghệ', 'sử dụng', 'cơ sở hạ tầng', 'hiện đại', 'để', 'hỗ trợ', 'sinh viên', 'và', 'dự án', 'nghiên cứu', 'end'], ['start', 'học viện', 'công nghệ thông tin', 'ptit', 'tại', 'hà nội', 'việt nam', 'được', 'thành lập', 'vào', 'năm', '2006', 'và', 'đã', 'nhanh chóng', 'phát triển', 'thành', 'một', 'trong', 'những', 'cơ sở', 'đào tạo', 'hàng đầu', 'về', 'công nghệ thông tin', 'ptit', 'cung cấp', 'nhiều', 'chương trình', 'đào tạo', 'cử nhân', 'và', 'thạc sĩ', 'trong', 'các', 'lĩnh vực', 'như', 'kỹ thuật', 'phần mềm', 'an toàn', 'thông tin', 'trí tuệ', 'nhân tạo', 'và', 'các', 'lĩnh vực', 'công nghệ', 'khác', 'ngoài ra', 'học viện', 'này', 'tích cực', 'tham gia', 'nghiên cứu', 'và', 'phát triển', 'công nghệ', 'sử dụng', 'cơ sở hạ tầng', 'hiện đại', 'để', 'hỗ trợ', 'sinh viên', 'và', 'dự án', 'nghiên cứu', 'end'], ['start', 'học viện', 'công nghệ thông tin', 'ptit', 'tại', 'hà nội', 'việt nam', 'được', 'thành lập', 'vào', 'năm', '2006', 'và', 'đã', 'nhanh chóng', 'phát triển', 'thành', 'một', 'trong', 'những', 'cơ sở', 'đào tạo', 'hàng đầu', 'về', 'công nghệ thông tin', 'ptit', 'cung cấp', 'nhiều', 'chương trình', 'đào tạo', 'cử nhân', 'và', 'thạc sĩ', 'trong', 'các', 'lĩnh vực', 'như', 'kỹ thuật', 'phần mềm', 'an toàn', 'thông tin', 'trí tuệ', 'nhân tạo', 'và', 'các', 'lĩnh vực', 'công nghệ', 'khác', 'ngoài ra', 'học viện', 'này', 'tích cực', 'tham gia', 'nghiên cứu', 'và', 'phát triển', 'công nghệ', 'sử dụng', 'cơ sở hạ tầng', 'hiện đại', 'để', 'hỗ trợ', 'sinh viên', 'và', 'dự án', 'nghiên cứu', 'end']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(questions + answers)\n",
        "VOCAB_SIZE = len(tokenizer.word_index) + 2\n",
        "print( 'VOCAB SIZE : {}'.format( VOCAB_SIZE ))"
      ],
      "metadata": {
        "id": "QsR71gvjKC1-",
        "outputId": "eac8ea83-1b9b-4ac7-c9f8-90f262d13175",
        "execution": {
          "iopub.status.busy": "2022-05-22T11:01:54.447707Z",
          "iopub.execute_input": "2022-05-22T11:01:54.447964Z",
          "iopub.status.idle": "2022-05-22T11:01:54.516863Z",
          "shell.execute_reply.started": "2022-05-22T11:01:54.447936Z",
          "shell.execute_reply": "2022-05-22T11:01:54.516009Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VOCAB SIZE : 255\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2idx = tokenizer.word_index"
      ],
      "metadata": {
        "id": "xRrlh0_NLe5g",
        "execution": {
          "iopub.status.busy": "2022-05-22T11:01:57.53376Z",
          "iopub.execute_input": "2022-05-22T11:01:57.534312Z",
          "iopub.status.idle": "2022-05-22T11:01:57.538207Z",
          "shell.execute_reply.started": "2022-05-22T11:01:57.534254Z",
          "shell.execute_reply": "2022-05-22T11:01:57.537319Z"
        },
        "trusted": true
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#encoder_input_data\n",
        "tokenized_questions = tokenizer.texts_to_sequences(questions)\n",
        "maxlen_questions = max([len(x) for x in tokenized_questions])\n",
        "padded_questions = pad_sequences(tokenized_questions, maxlen = maxlen_questions, padding = 'post')\n",
        "encoder_input_data = np.array(padded_questions)\n",
        "print(\"Max length question:\", maxlen_questions)\n",
        "print(encoder_input_data.shape)"
      ],
      "metadata": {
        "id": "LRbibHDuKqY0",
        "outputId": "dcb4769a-185b-47eb-8836-7655e33aa3ec",
        "execution": {
          "iopub.status.busy": "2022-05-22T11:02:00.491228Z",
          "iopub.execute_input": "2022-05-22T11:02:00.491795Z",
          "iopub.status.idle": "2022-05-22T11:02:00.542046Z",
          "shell.execute_reply.started": "2022-05-22T11:02:00.491755Z",
          "shell.execute_reply": "2022-05-22T11:02:00.541194Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max length question: 12\n",
            "(105, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# decoder_input_data\n",
        "tokenized_answers = tokenizer.texts_to_sequences(answers)\n",
        "maxlen_answers = max([len(x) for x in tokenized_answers])\n",
        "padded_answers = pad_sequences(tokenized_answers, maxlen = maxlen_answers, padding='post')\n",
        "decoder_input_data = np.array(padded_answers)\n",
        "print(\"Max length anwser:\", maxlen_answers)\n",
        "print(decoder_input_data.shape)"
      ],
      "metadata": {
        "id": "FSuEOE4rLCzo",
        "execution": {
          "iopub.status.busy": "2022-05-22T11:02:03.364843Z",
          "iopub.execute_input": "2022-05-22T11:02:03.365538Z",
          "iopub.status.idle": "2022-05-22T11:02:03.416977Z",
          "shell.execute_reply.started": "2022-05-22T11:02:03.365497Z",
          "shell.execute_reply": "2022-05-22T11:02:03.415783Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04fcb0b7-7eee-4122-ef8e-09a0f6042842"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max length anwser: 67\n",
            "(105, 67)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# decoder_output_data\n",
        "tokenized_answers = tokenizer.texts_to_sequences(answers)\n",
        "# Remove Start added before\n",
        "for i in range(len(tokenized_answers)):\n",
        "    tokenized_answers[i] = tokenized_answers[i][1:]\n",
        "padded_answers = pad_sequences(tokenized_answers, maxlen = maxlen_answers, padding='post')\n",
        "decoder_output_data = np.array(padded_answers)\n",
        "print(decoder_output_data.shape)"
      ],
      "metadata": {
        "id": "AEHXML0aLRx9",
        "outputId": "d89fadff-3c7c-4b53-b2d7-f00200e95376",
        "execution": {
          "iopub.status.busy": "2022-05-22T11:06:51.262879Z",
          "iopub.execute_input": "2022-05-22T11:06:51.263175Z",
          "iopub.status.idle": "2022-05-22T11:06:51.316964Z",
          "shell.execute_reply.started": "2022-05-22T11:06:51.263144Z",
          "shell.execute_reply": "2022-05-22T11:06:51.316095Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(105, 67)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/do_an/wiki.vi.vec.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYG_KWW-Gzh1",
        "outputId": "894a0c6b-97ba-4014-ec30-e625f9e3c71c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/do_an/wiki.vi.vec.zip\n",
            "  inflating: wiki.vi.vec             \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Word2Vec Embedding with FastText**"
      ],
      "metadata": {
        "id": "XIRPpLBYyhwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fastText_model = KeyedVectors.load_word2vec_format('/content/wiki.vi.vec')\n",
        "print(\"FastText Loaded!\")"
      ],
      "metadata": {
        "id": "cu2AjHISyhwG",
        "execution": {
          "iopub.status.busy": "2022-05-22T11:06:51.3187Z",
          "iopub.execute_input": "2022-05-22T11:06:51.319017Z",
          "iopub.status.idle": "2022-05-22T11:07:52.781538Z",
          "shell.execute_reply.started": "2022-05-22T11:06:51.31898Z",
          "shell.execute_reply": "2022-05-22T11:07:52.779955Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_dim = 300\n",
        "\n",
        "embedding_matrix = np.zeros((VOCAB_SIZE, embeddings_dim))\n",
        "\n",
        "for word, index in word2idx.items():\n",
        "    try:\n",
        "        embedding_matrix[index,:] = fastText_model[word]\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "print(embedding_matrix.shape)"
      ],
      "metadata": {
        "id": "aqRqb_KYyhwG",
        "execution": {
          "iopub.status.busy": "2022-05-22T11:07:52.782831Z",
          "iopub.execute_input": "2022-05-22T11:07:52.783162Z",
          "iopub.status.idle": "2022-05-22T11:07:52.807759Z",
          "shell.execute_reply.started": "2022-05-22T11:07:52.783122Z",
          "shell.execute_reply": "2022-05-22T11:07:52.806981Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer Structure"
      ],
      "metadata": {
        "id": "42LdbeUiAWUj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ta có thể thấy lớp Encoder gồm N khối (ta tạm gọi là EncoderLayer). Và đầu ra của N khối này sẽ được nối sang bên Decoder. Tương tự với đó là bên Decoder cũng chứa N khối DecoderLayer."
      ],
      "metadata": {
        "id": "RO71usQ7AWUj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoder:\n",
        "- Gồm lớp Embedding, Positional Encoding và các lớp Encoder\n",
        "## Lớp Encoder:\n",
        "- Gồm lớp Multi-Head Attention, 2 lớp Add & Norm và 1 mạng Feed Forward\n",
        "\n",
        "### Decoder:\n",
        "- Gồm lớp Embedding, Positional Encoding và các lớp Decoder\n",
        "## Lớp Encoder:\n",
        "- Gồm lớp 3 khối:\n",
        " + Masked Multi-Head Attention, 1 lớp Add & Norm\n",
        " + Multi-Head Attention nhận 2 ma trận K,V từ lớp encoder, 1 lớp Add & Norm\n",
        " + 1 mạng Feed Forward và 1 lớp Add & Norm\n",
        "\n",
        "### Đi qua một mạng Linear và Softmax để có được output"
      ],
      "metadata": {
        "id": "jRT1ZmxbAWUj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Defination"
      ],
      "metadata": {
        "id": "GMCTx2fdyhwG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attension"
      ],
      "metadata": {
        "id": "6u4xoOQ4AWUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "  \"\"\"Calculate the attention weights. \"\"\"\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "  # scale matmul_qk\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "  # add the mask to zero out padding tokens\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9)\n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k)\n",
        "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "  output = tf.matmul(attention_weights, value)\n",
        "\n",
        "  return output"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T11:07:52.81018Z",
          "iopub.execute_input": "2022-05-22T11:07:52.810508Z",
          "iopub.status.idle": "2022-05-22T11:07:52.816614Z",
          "shell.execute_reply.started": "2022-05-22T11:07:52.81047Z",
          "shell.execute_reply": "2022-05-22T11:07:52.81579Z"
        },
        "trusted": true,
        "id": "6JOIwe9aAWUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "    super(MultiHeadAttention, self).__init__(name=name)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(\n",
        "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
        "        'value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    # linear layers\n",
        "    query = self.query_dense(query)\n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    # split heads\n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    # scaled dot-product attention\n",
        "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "    # concatenation of heads\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))\n",
        "\n",
        "    # final linear layer\n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T11:07:52.817886Z",
          "iopub.execute_input": "2022-05-22T11:07:52.818141Z",
          "iopub.status.idle": "2022-05-22T11:07:52.837984Z",
          "shell.execute_reply.started": "2022-05-22T11:07:52.818105Z",
          "shell.execute_reply": "2022-05-22T11:07:52.837277Z"
        },
        "trusted": true,
        "id": "d58D0YzpAWUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Masking"
      ],
      "metadata": {
        "id": "38etLV73AWUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_padding_mask(x):\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "  # (batch_size, 1, 1, sequence length)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T11:07:52.840294Z",
          "iopub.execute_input": "2022-05-22T11:07:52.840546Z",
          "iopub.status.idle": "2022-05-22T11:07:52.851079Z",
          "shell.execute_reply.started": "2022-05-22T11:07:52.840517Z",
          "shell.execute_reply": "2022-05-22T11:07:52.850373Z"
        },
        "trusted": true,
        "id": "YCzPAuogAWUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_look_ahead_mask(x):\n",
        "  seq_len = tf.shape(x)[1]\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "  padding_mask = create_padding_mask(x)\n",
        "  return tf.maximum(look_ahead_mask, padding_mask)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T11:07:52.85251Z",
          "iopub.execute_input": "2022-05-22T11:07:52.852908Z",
          "iopub.status.idle": "2022-05-22T11:07:52.860169Z",
          "shell.execute_reply.started": "2022-05-22T11:07:52.85287Z",
          "shell.execute_reply": "2022-05-22T11:07:52.859411Z"
        },
        "trusted": true,
        "id": "edB6PTAHAWUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Positional Encoding"
      ],
      "metadata": {
        "id": "YfVO0t40AWUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, position, d_model):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles\n",
        "\n",
        "  def positional_encoding(self, position, d_model):\n",
        "    angle_rads = self.get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model=d_model)\n",
        "    # apply sin to even index in the array\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "    # apply cos to odd index in the array\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T11:07:52.861502Z",
          "iopub.execute_input": "2022-05-22T11:07:52.862425Z",
          "iopub.status.idle": "2022-05-22T11:07:52.873252Z",
          "shell.execute_reply.started": "2022-05-22T11:07:52.862387Z",
          "shell.execute_reply": "2022-05-22T11:07:52.872521Z"
        },
        "trusted": true,
        "id": "S_IaTHymAWUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder Layer"
      ],
      "metadata": {
        "id": "qvJz6hKfAWUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "  attention = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T11:07:52.874535Z",
          "iopub.execute_input": "2022-05-22T11:07:52.875191Z",
          "iopub.status.idle": "2022-05-22T11:07:52.897771Z",
          "shell.execute_reply.started": "2022-05-22T11:07:52.875153Z",
          "shell.execute_reply": "2022-05-22T11:07:52.896997Z"
        },
        "trusted": true,
        "id": "-7tB85nKAWUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder"
      ],
      "metadata": {
        "id": "CMQPxkdVAWUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name=\"encoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size,d_model\n",
        "                                     ,input_length=maxlen_questions\n",
        "                                     ,weights = [embedding_matrix]\n",
        "                                     ,trainable=False)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name=\"encoder_layer_{}\".format(i),\n",
        "    )([outputs, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T11:07:52.901093Z",
          "iopub.execute_input": "2022-05-22T11:07:52.901536Z",
          "iopub.status.idle": "2022-05-22T11:07:52.910685Z",
          "shell.execute_reply.started": "2022-05-22T11:07:52.901499Z",
          "shell.execute_reply": "2022-05-22T11:07:52.909892Z"
        },
        "trusted": true,
        "id": "0cA_PkGzAWUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder Layer"
      ],
      "metadata": {
        "id": "mwHVCivHAWUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "  attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': look_ahead_mask\n",
        "      })\n",
        "  attention1 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "  attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query': attention1,\n",
        "          'key': enc_outputs,\n",
        "          'value': enc_outputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "  attention2 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T11:07:52.911897Z",
          "iopub.execute_input": "2022-05-22T11:07:52.912312Z",
          "iopub.status.idle": "2022-05-22T11:07:52.925079Z",
          "shell.execute_reply.started": "2022-05-22T11:07:52.912262Z",
          "shell.execute_reply": "2022-05-22T11:07:52.924327Z"
        },
        "trusted": true,
        "id": "zTW63iEjAWUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder"
      ],
      "metadata": {
        "id": "v4rP0U2EAWUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name='decoder'):\n",
        "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name='look_ahead_mask')\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size,d_model\n",
        "                                     ,input_length=maxlen_answers\n",
        "                                     ,weights = [embedding_matrix]\n",
        "                                     ,trainable=False)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name='decoder_layer_{}'.format(i),\n",
        "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T11:07:52.926428Z",
          "iopub.execute_input": "2022-05-22T11:07:52.92686Z",
          "iopub.status.idle": "2022-05-22T11:07:52.939175Z",
          "shell.execute_reply.started": "2022-05-22T11:07:52.926822Z",
          "shell.execute_reply": "2022-05-22T11:07:52.93827Z"
        },
        "trusted": true,
        "id": "047U32lmAWUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer"
      ],
      "metadata": {
        "id": "UAjAi9kOAWUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer(vocab_size,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                name=\"transformer\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(inputs)\n",
        "  # mask the future tokens for decoder inputs at the 1st attention block\n",
        "  look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask,\n",
        "      output_shape=(1, None, None),\n",
        "      name='look_ahead_mask')(dec_inputs)\n",
        "  # mask the encoder outputs for the 2nd attention block\n",
        "  dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='dec_padding_mask')(inputs)\n",
        "\n",
        "  enc_outputs = encoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "  dec_outputs = decoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size)(dec_outputs)\n",
        "  #Add a softmax layer to get probability distribution of word in vocab\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size, activation = 'softmax',name = \"outputs\")(outputs)\n",
        "\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T11:07:52.940566Z",
          "iopub.execute_input": "2022-05-22T11:07:52.940982Z",
          "iopub.status.idle": "2022-05-22T11:07:52.953347Z",
          "shell.execute_reply.started": "2022-05-22T11:07:52.940941Z",
          "shell.execute_reply": "2022-05-22T11:07:52.952587Z"
        },
        "trusted": true,
        "id": "fHJIKRVhAWUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Hyper-parameters\n",
        "NUM_LAYERS = 2\n",
        "NUM_HEADS = 6 # model dims must divided to number of heads\n",
        "UNITS = 512\n",
        "DROPOUT = 0.1"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T11:07:52.955272Z",
          "iopub.execute_input": "2022-05-22T11:07:52.957378Z",
          "iopub.status.idle": "2022-05-22T11:07:52.97036Z",
          "shell.execute_reply.started": "2022-05-22T11:07:52.957339Z",
          "shell.execute_reply": "2022-05-22T11:07:52.969565Z"
        },
        "trusted": true,
        "id": "0p5jJse5AWUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=embeddings_dim,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T11:07:52.973225Z",
          "iopub.execute_input": "2022-05-22T11:07:52.973697Z",
          "iopub.status.idle": "2022-05-22T11:07:56.608783Z",
          "shell.execute_reply.started": "2022-05-22T11:07:52.973659Z",
          "shell.execute_reply": "2022-05-22T11:07:56.607883Z"
        },
        "trusted": true,
        "id": "wJYSCyJPAWUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T11:07:56.610214Z",
          "iopub.execute_input": "2022-05-22T11:07:56.610653Z",
          "iopub.status.idle": "2022-05-22T11:07:56.628238Z",
          "shell.execute_reply.started": "2022-05-22T11:07:56.610584Z",
          "shell.execute_reply": "2022-05-22T11:07:56.627495Z"
        },
        "trusted": true,
        "id": "Pzs4S5-CAWUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Loss Function"
      ],
      "metadata": {
        "id": "MfM7mATmAWUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, maxlen_answers))\n",
        "\n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none')(y_true, y_pred)\n",
        "\n",
        "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
        "  loss = tf.multiply(loss, mask)\n",
        "\n",
        "  return tf.reduce_mean(loss)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T11:07:56.629693Z",
          "iopub.execute_input": "2022-05-22T11:07:56.630001Z",
          "iopub.status.idle": "2022-05-22T11:07:56.635959Z",
          "shell.execute_reply.started": "2022-05-22T11:07:56.629955Z",
          "shell.execute_reply": "2022-05-22T11:07:56.634882Z"
        },
        "trusted": true,
        "id": "cE4nZ87aAWUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizer with custom learning rate"
      ],
      "metadata": {
        "id": "qk4asw81AWUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "  def __init__(self, d_model, warmup_steps=2000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  # def get_config(self):\n",
        "  #       return {\n",
        "  #           'd_model': self.d_model.numpy(),  # since self.d_model is a tf.Tensor\n",
        "  #           'warmup_steps': self.warmup_steps\n",
        "  #       }\n",
        "\n",
        "  def __call__(self, step):\n",
        "    step = tf.cast(step, tf.float32)\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T11:07:56.637812Z",
          "iopub.execute_input": "2022-05-22T11:07:56.638179Z",
          "iopub.status.idle": "2022-05-22T11:07:56.648983Z",
          "shell.execute_reply.started": "2022-05-22T11:07:56.638145Z",
          "shell.execute_reply": "2022-05-22T11:07:56.648028Z"
        },
        "trusted": true,
        "id": "lhMaOHIuAWUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(embeddings_dim)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T11:07:56.650648Z",
          "iopub.execute_input": "2022-05-22T11:07:56.650908Z",
          "iopub.status.idle": "2022-05-22T11:07:56.658551Z",
          "shell.execute_reply.started": "2022-05-22T11:07:56.650874Z",
          "shell.execute_reply": "2022-05-22T11:07:56.657602Z"
        },
        "trusted": true,
        "id": "97I5wFNzAWUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile the model"
      ],
      "metadata": {
        "id": "vAocEEPFAWUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, maxlen_answers))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T11:07:56.660007Z",
          "iopub.execute_input": "2022-05-22T11:07:56.660665Z",
          "iopub.status.idle": "2022-05-22T11:07:56.668379Z",
          "shell.execute_reply.started": "2022-05-22T11:07:56.660626Z",
          "shell.execute_reply": "2022-05-22T11:07:56.667613Z"
        },
        "trusted": true,
        "id": "GWUD84Q1AWUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T11:07:56.67061Z",
          "iopub.execute_input": "2022-05-22T11:07:56.670876Z",
          "iopub.status.idle": "2022-05-22T11:07:56.687373Z",
          "shell.execute_reply.started": "2022-05-22T11:07:56.670837Z",
          "shell.execute_reply": "2022-05-22T11:07:56.686627Z"
        },
        "trusted": true,
        "id": "GI3jonZ9AWUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "history = model.fit([encoder_input_data , decoder_input_data], decoder_output_data, batch_size=64, epochs=5)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T11:07:56.689604Z",
          "iopub.execute_input": "2022-05-22T11:07:56.690377Z",
          "iopub.status.idle": "2022-05-22T11:08:43.362403Z",
          "shell.execute_reply.started": "2022-05-22T11:07:56.690266Z",
          "shell.execute_reply": "2022-05-22T11:08:43.361719Z"
        },
        "trusted": true,
        "id": "fSpmX7jXAWUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize Training Progress"
      ],
      "metadata": {
        "id": "eH1yQPSRyhwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'],label='Training_loss')\n",
        "plt.legend()\n",
        "plt.title('Training loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()\n",
        "plt.savefig('Loss_Graph')"
      ],
      "metadata": {
        "id": "w4JcHuaJyhwH",
        "execution": {
          "iopub.status.busy": "2022-05-22T11:08:43.363813Z",
          "iopub.execute_input": "2022-05-22T11:08:43.364107Z",
          "iopub.status.idle": "2022-05-22T11:08:43.571703Z",
          "shell.execute_reply.started": "2022-05-22T11:08:43.364062Z",
          "shell.execute_reply": "2022-05-22T11:08:43.570936Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('chatbot_weights.h5')"
      ],
      "metadata": {
        "id": "Wt1s-hbuyhwH",
        "execution": {
          "iopub.status.busy": "2022-05-22T11:08:43.572733Z",
          "iopub.execute_input": "2022-05-22T11:08:43.573276Z",
          "iopub.status.idle": "2022-05-22T11:08:43.821383Z",
          "shell.execute_reply.started": "2022-05-22T11:08:43.573232Z",
          "shell.execute_reply": "2022-05-22T11:08:43.820569Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save(\"my_model.keras\")"
      ],
      "metadata": {
        "id": "FSrPofS7tCLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bot Chatting"
      ],
      "metadata": {
        "id": "G2eRhxJTyhwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idx2word = tokenizer.index_word"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T11:08:43.822661Z",
          "iopub.execute_input": "2022-05-22T11:08:43.822948Z",
          "iopub.status.idle": "2022-05-22T11:08:43.827872Z",
          "shell.execute_reply.started": "2022-05-22T11:08:43.822911Z",
          "shell.execute_reply": "2022-05-22T11:08:43.827051Z"
        },
        "trusted": true,
        "id": "nVWKm6jRAWUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def str_to_tokens(sentence):\n",
        "    words = word_tokenize(sentence.lower())\n",
        "    tokens_list = []\n",
        "\n",
        "    for word in words:\n",
        "        tokens_list.append(word2idx[word])\n",
        "    return pad_sequences([tokens_list],maxlen = maxlen_questions , padding='post')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T11:08:43.829147Z",
          "iopub.execute_input": "2022-05-22T11:08:43.82958Z",
          "iopub.status.idle": "2022-05-22T11:08:43.838176Z",
          "shell.execute_reply.started": "2022-05-22T11:08:43.829541Z",
          "shell.execute_reply": "2022-05-22T11:08:43.83736Z"
        },
        "trusted": true,
        "id": "kW1cAigGAWUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(sentence):\n",
        "  sentence = str_to_tokens(sentence)\n",
        "  output = np.zeros((1, 1))\n",
        "  output[0, 0] = word2idx['start']\n",
        "\n",
        "  for i in range(maxlen_answers):\n",
        "    predictions = model(inputs=[sentence, output], training=False)\n",
        "\n",
        "    # select the last word from the seq_len dimension\n",
        "    predictions = predictions[:, -1:, :]\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "    if tf.equal(predicted_id, word2idx['end']):\n",
        "      break\n",
        "\n",
        "    # concatenated the predicted_id to the output which is given to the decoder as its input.\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output, axis=0)\n",
        "\n",
        "def predict(sentence):\n",
        "  prediction = evaluate(sentence)\n",
        "  predicted_sentence = \" \".join(idx2word[tf.get_static_value(i)] for i in prediction if i < VOCAB_SIZE)\n",
        "  return predicted_sentence.replace(\"start\",\"\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T11:08:43.839453Z",
          "iopub.execute_input": "2022-05-22T11:08:43.839726Z",
          "iopub.status.idle": "2022-05-22T11:08:43.848736Z",
          "shell.execute_reply.started": "2022-05-22T11:08:43.839688Z",
          "shell.execute_reply": "2022-05-22T11:08:43.848058Z"
        },
        "trusted": true,
        "id": "d7T5Y3tCAWU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flag=True\n",
        "print(\"BOT: Xin chào! Tôi là ChatBot. Nếu bạn muốn ngưng cuộc trò chuyện, hãy gõ Bye!\")\n",
        "\n",
        "human_response = \"thông tin trường bưu chính\"\n",
        "if human_response != 'bye':\n",
        "    try:\n",
        "        print('BOT: ' + predict(human_response))\n",
        "    except:\n",
        "        print(\"BOT: Xin lỗi câu này tôi chưa đc học ,vui lòng hỏi lại :( \")\n",
        "else:\n",
        "    flag=False\n",
        "    print(\"BOT: Tạm biệt nha!\")"
      ],
      "metadata": {
        "id": "mjaicXTBUBC7",
        "execution": {
          "iopub.status.busy": "2022-05-22T11:08:43.852247Z",
          "iopub.execute_input": "2022-05-22T11:08:43.852489Z",
          "iopub.status.idle": "2022-05-22T11:09:32.199125Z",
          "shell.execute_reply.started": "2022-05-22T11:08:43.852448Z",
          "shell.execute_reply": "2022-05-22T11:09:32.197692Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}